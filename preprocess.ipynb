{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import dask.distributed\n",
    "import dask.utils\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Dask client for parallel processing\n",
    "client = dask.distributed.Client()\n",
    "configure_rio(cloud_defaults=True, client=client)\n",
    "\n",
    "# Configure rio with dynamic resolution\n",
    "resolution = 20\n",
    "memory_limit = dask.utils.parse_bytes(client.cluster.workers[0].memory_manager.memory_limit)\n",
    "SHRINK = 4\n",
    "if memory_limit < dask.utils.parse_bytes(\"4G\"):\n",
    "    SHRINK = 8  # Adjust chunk size if memory is limited\n",
    "\n",
    "resolution = resolution * SHRINK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest (AOI) for Lake Michigan\n",
    "area_of_interest = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [-88.2, 43.0],  # Lower-left corner\n",
    "            [-86.1, 43.0],  # Lower-right corner\n",
    "            [-86.1, 45.0],  # Upper-right corner\n",
    "            [-88.2, 45.0],  # Upper-left corner\n",
    "            [-88.2, 43.0],  # Closing the polygon\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "#  time span of 10 years\n",
    "time_of_interest = \"2013-06-01/2023-06-01\"\n",
    "\n",
    "# Query the catalog for the data\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "search = catalog.search(\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    intersects=area_of_interest,\n",
    "    datetime=time_of_interest\n",
    ")\n",
    "items = list(search.items())\n",
    "print(f\"Returned {len(items)} Items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the catalog with dynamic chunking and handle missing data\n",
    "xx = stac_load(\n",
    "    items,\n",
    "    chunks={\"x\": 1024 * SHRINK, \"y\": 1024 * SHRINK},  # Dynamically adjust chunk size\n",
    "    patch_url=planetary_computer.sign,\n",
    "    resolution=resolution,\n",
    "    dtype=\"uint16\",  # Handle missing data by marking nodata values\n",
    "    nodata=0\n",
    ")\n",
    "\n",
    "# Display loaded data\n",
    "print(f\"Bands: {','.join(list(xx.data_vars))}\")\n",
    "display(xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert data to float and handle missing nodata values\n",
    "def to_float(xx, nodata_value=None):\n",
    "    _xx = xx.astype(\"float32\")  # Convert data to float32 for precision\n",
    "    if nodata_value is None:\n",
    "        nodata_value = _xx.attrs.pop(\"nodata\", None)  # Fetch nodata value if exists\n",
    "    if nodata_value is not None:\n",
    "        return _xx.where(xx != nodata_value)  # Replace nodata with NaN\n",
    "    return _xx\n",
    "\n",
    "# Convert specific bands to float32 and handle missing data\n",
    "b05 = to_float(xx.B05)  # Red-Edge band\n",
    "b04 = to_float(xx.B04)  # Red band\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDCI with small constant to avoid division by zero\n",
    "ndci = (b05 - b04) / (b05 + b04 + 1e-6)\n",
    "\n",
    "# Apply Min-Max normalization to scale NDCI between 0 and 1\n",
    "ndci = (ndci - ndci.min()) / (ndci.max() - ndci.min())\n",
    "\n",
    "# Display the calculated NDCI\n",
    "display(ndci)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient concatenation of NDCI across the time dimension\n",
    "ndci_comp = xr.concat([ndci.isel(time=i) for i in range(len(ndci))], dim=\"time\").compute()\n",
    "\n",
    "# Display concatenated time series\n",
    "print(ndci_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am trying to visualize the NDCI index for verification. This step is additional and not part of the notebook provided to us \n",
    "_ = ndci.isel(time=335).compute().plot.imshow(size=7, aspect=1.2, interpolation=\"bicubic\")\n",
    "\n",
    "# Loop through time steps to visualize the time series\n",
    "for i in range(0, len(ndci), 50):  # Every 50th time step\n",
    "    plt.figure()\n",
    "    ndci.isel(time=i).compute().plot.imshow(size=7, aspect=1.2, interpolation=\"bicubic\")\n",
    "    plt.title(f\"NDCI - Time step {i}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
